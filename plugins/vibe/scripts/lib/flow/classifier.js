#!/usr/bin/env node
/**
 * classifier.js â€” LLM-first åˆ†é¡å™¨
 *
 * è¨­è¨ˆåŸå‰‡ï¼š
 *   ç”¨ LLM ç†è§£è‡ªç„¶èªè¨€æ„åœ–ï¼Œä¸é  regex çŒœæ¸¬ã€‚
 *   ä½¿ç”¨è€…ä¸éœ€è¦åˆ†æè‡ªå·±çš„æªè¾­ï¼Œä¹Ÿä¸éœ€è¦åŠ  [pipeline:xxx] æ¨™ç±¤ã€‚
 *
 * å…©å±¤æ¶æ§‹ï¼š
 *   Layer 1:  Explicit Pipeline â€” [pipeline:xxx] èªæ³•ï¼ˆ100% ä¿¡å¿ƒåº¦ï¼Œé›¶æˆæœ¬ï¼‰
 *   Layer 2:  LLM Classification â€” Sonnet èªæ„åˆ†é¡ï¼ˆä¸»è¦è·¯å¾‘ï¼‰
 *   Fallback: API ä¸å¯ç”¨ â†’ pipeline:none + additionalContext æç¤º
 *
 * ç’°å¢ƒè®Šæ•¸ï¼š
 *   VIBE_CLASSIFIER_MODEL â€” LLM æ¨¡å‹ï¼ˆé è¨­ claude-sonnet-4-20250514ï¼‰
 *   VIBE_CLASSIFIER_THRESHOLD â€” è¨­ 1.0 åœç”¨ LLMï¼ˆé™ç´šç‚º fallbackï¼‰
 *
 * @module flow/classifier
 */
'use strict';

const https = require('https');
const { PIPELINES, TASKTYPE_TO_PIPELINE, PIPELINE_TO_TASKTYPE } = require('../registry.js');

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Layer 1: é¡¯å¼ Pipeline è¦†å¯«
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * è§£æé¡¯å¼ pipeline èªæ³• [pipeline:xxx]
 * @param {string} prompt - ä½¿ç”¨è€…è¼¸å…¥ï¼ˆåŸå§‹æ–‡å­—ï¼‰
 * @returns {string|null} pipeline ID æˆ– nullï¼ˆå¤§å°å¯«ä¸æ•æ„Ÿï¼‰
 */
function extractExplicitPipeline(prompt) {
  if (!prompt) return null;

  const match = prompt.match(/\[pipeline:([a-z0-9-]+)\]/i);
  if (!match) return null;

  const pipelineId = match[1].toLowerCase();
  if (!PIPELINES[pipelineId]) return null;

  return pipelineId;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Layer 2: LLM åˆ†é¡ï¼ˆä¸»è¦è·¯å¾‘ï¼‰
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/** LLM æ¨¡å‹ï¼ˆç’°å¢ƒè®Šæ•¸å¯è¦†å¯«ï¼‰ */
const LLM_MODEL = process.env.VIBE_CLASSIFIER_MODEL || 'claude-sonnet-4-20250514';

/** LLM å‘¼å«é€¾æ™‚ï¼ˆmsï¼‰ */
const LLM_TIMEOUT = 10000;

/**
 * å°‡ taskType æ˜ å°„åˆ° pipeline ID
 * @param {string} taskType
 * @returns {string} pipeline ID
 */
function mapTaskTypeToPipeline(taskType) {
  return TASKTYPE_TO_PIPELINE[taskType] || 'fix';
}

/**
 * å‘¼å« Anthropic API é€²è¡Œèªæ„åˆ†é¡
 *
 * @param {string} prompt - ä½¿ç”¨è€…è¼¸å…¥
 * @returns {Promise<{pipeline: string, confidence: number, source: 'llm', matchedRule: string}|null>}
 */
function classifyWithLLM(prompt) {
  const apiKey = process.env.ANTHROPIC_API_KEY;
  if (!apiKey) return Promise.resolve(null);

  // ç’°å¢ƒè®Šæ•¸å¯åœç”¨ LLM
  const threshold = parseFloat(process.env.VIBE_CLASSIFIER_THRESHOLD);
  if (!Number.isNaN(threshold) && threshold >= 1.0) return Promise.resolve(null);

  const catalog = Object.entries(PIPELINES)
    .map(([id, p]) => `- ${id}: ${p.description}`)
    .join('\n');

  const systemPrompt = [
    'ä½ æ˜¯é–‹ç™¼ä»»å‹™åˆ†é¡å™¨ã€‚æ ¹æ“šä½¿ç”¨è€…çš„è‡ªç„¶èªè¨€è¼¸å…¥ï¼Œåˆ¤æ–·æœ€é©åˆçš„é–‹ç™¼ pipelineã€‚',
    '',
    'é—œéµåŸå‰‡ï¼šåˆ†æä½¿ç”¨è€…çš„ä¸»è¦æ„åœ–ï¼Œä¸è¦è¢«é™„å±¬å­å¥çš„æªè¾­å¹²æ“¾ã€‚',
    'ä¾‹å¦‚ã€Œç¹¼çºŒå°‹æ‰¾æœ‰æ²’æœ‰éºç•™è·Ÿæ–·è£‚ä¸¦å„ªåŒ–ã€â†’ ä¸»æ„åœ–æ˜¯ã€Œå„ªåŒ–/é‡æ§‹ã€ï¼Œä¸æ˜¯å•å•é¡Œã€‚',
    'ä¾‹å¦‚ã€Œå¹«æˆ‘çœ‹çœ‹é€™å€‹ bug ç„¶å¾Œä¿®æ‰ã€â†’ ä¸»æ„åœ–æ˜¯ã€Œä¿® bugã€ï¼Œä¸æ˜¯ã€Œçœ‹çœ‹ã€ã€‚',
    '',
    'åªå›è¦†ä¸€å€‹ JSON ç‰©ä»¶ï¼š{"pipeline":"<id>"}',
    '',
    'å¯ç”¨ pipelineï¼š',
    catalog,
    '',
    'åˆ†é¡åŸå‰‡ï¼š',
    '- ç´”ç²¹å•å•é¡Œã€æŸ¥è³‡æ–™ã€æ¢ç´¢ã€èŠå¤©ã€æ‰“æ‹›å‘¼ â†’ none',
    '- ä¿® typoã€æ”¹åã€æ”¹è¨­å®šã€ä¸€è¡Œä¿®æ”¹ â†’ fix',
    '- Bug ä¿®å¾© + éœ€è¦æ¸¬è©¦é©—è­‰ â†’ quick-dev',
    '- æ–°åŠŸèƒ½ã€æ–°ç³»çµ±ã€æ–°æ¨¡çµ„ï¼ˆå« UIï¼‰â†’ full',
    '- æ–°åŠŸèƒ½ã€æ–°ç³»çµ±ã€æ–°æ¨¡çµ„ï¼ˆç„¡ UIï¼‰â†’ standard',
    '- é‡æ§‹ã€å„ªåŒ–ã€æ”¹å–„ã€æ”¹é€²æ—¢æœ‰ç¨‹å¼ç¢¼ â†’ standard',
    '- TDD å·¥ä½œæµï¼ˆå…ˆå¯«æ¸¬è©¦å†å¯¦ä½œï¼‰â†’ test-first',
    '- ç´” UI/æ¨£å¼èª¿æ•´ â†’ ui-only',
    '- ç¨‹å¼ç¢¼å¯©æŸ¥ â†’ review-only',
    '- ç´”æ–‡ä»¶æ›´æ–°ï¼ˆ.md/README/CHANGELOGï¼‰â†’ docs-only',
    '- å®‰å…¨æ¼æ´ä¿®å¾© â†’ security',
    '- ä¸ç¢ºå®šæ™‚é¸ noneï¼ˆä¿å®ˆç­–ç•¥ï¼‰',
  ].join('\n');

  const body = JSON.stringify({
    model: LLM_MODEL,
    max_tokens: 60,
    messages: [{ role: 'user', content: prompt.slice(0, 500) }],
    system: systemPrompt,
  });

  return new Promise((resolve) => {
    const req = https.request({
      hostname: 'api.anthropic.com',
      path: '/v1/messages',
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': apiKey,
        'anthropic-version': '2024-10-22',
        'Content-Length': Buffer.byteLength(body),
      },
    }, (res) => {
      let data = '';
      res.on('data', chunk => data += chunk);
      res.on('end', () => {
        if (res.statusCode !== 200) { resolve(null); return; }
        try {
          const parsed = JSON.parse(data);
          const text = (parsed.content && parsed.content[0] && parsed.content[0].text) || '';
          const match = text.match(/\{[^}]+\}/);
          if (!match) { resolve(null); return; }
          const result = JSON.parse(match[0]);
          if (!result.pipeline || !PIPELINES[result.pipeline]) { resolve(null); return; }
          resolve({ pipeline: result.pipeline, confidence: 0.85, source: 'llm', matchedRule: 'llm' });
        } catch (_) { resolve(null); }
      });
    });

    req.on('error', () => resolve(null));
    req.setTimeout(LLM_TIMEOUT, () => { req.destroy(); resolve(null); });
    req.write(body);
    req.end();
  });
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ä¸»è¦ API
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * LLM-first åˆ†é¡ï¼ˆasyncï¼‰
 *
 * Layer 1: é¡¯å¼ [pipeline:xxx] â†’ ç›´æ¥è¿”å›
 * Layer 2: LLM èªæ„åˆ†é¡ â†’ ä¸»è¦è·¯å¾‘
 * Fallback: API ä¸å¯ç”¨ â†’ none + æç¤º
 *
 * @param {string} prompt
 * @returns {Promise<{ pipeline: string, confidence: number, source: string, matchedRule: string }>}
 */
async function classifyWithConfidence(prompt) {
  if (!prompt || !prompt.trim()) {
    return { pipeline: 'none', confidence: 0, source: 'fallback', matchedRule: 'empty' };
  }

  // Layer 1: é¡¯å¼è¦†å¯«
  const explicitPipeline = extractExplicitPipeline(prompt);
  if (explicitPipeline) {
    return { pipeline: explicitPipeline, confidence: 1.0, source: 'explicit', matchedRule: 'explicit' };
  }

  // Layer 2: LLM åˆ†é¡
  const llmResult = await classifyWithLLM(prompt);
  if (llmResult) {
    return llmResult;
  }

  // Fallback: API ä¸å¯ç”¨
  return { pipeline: 'none', confidence: 0, source: 'fallback', matchedRule: 'api-unavailable' };
}

/**
 * ç”¢ç”Ÿ Pipeline ç›®éŒ„æç¤ºï¼ˆFallback æ™‚æ³¨å…¥ additionalContextï¼‰
 * @returns {string}
 */
function buildPipelineCatalogHint() {
  const catalog = Object.entries(PIPELINES)
    .filter(([id]) => id !== 'none')
    .map(([id, p]) => `  [pipeline:${id}] â€” ${p.label}ï¼š${p.description}`)
    .join('\n');

  return '\nğŸ’¡ LLM åˆ†é¡å™¨ä¸å¯ç”¨ã€‚å¯åœ¨ prompt ä¸­åŠ ä¸Šèªæ³•è¦†å¯«ï¼š\n' + catalog;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// åŒ¯å‡º
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

module.exports = {
  // ä¸»è¦ APIï¼ˆasyncï¼‰
  classifyWithConfidence,
  classifyWithLLM,

  // å·¥å…·å‡½å¼
  extractExplicitPipeline,
  mapTaskTypeToPipeline,
  buildPipelineCatalogHint,

  // å¸¸é‡ï¼ˆä¾›æ¸¬è©¦ï¼‰
  LLM_MODEL,
  LLM_TIMEOUT,
};
